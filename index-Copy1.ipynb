{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lasso and ridge regression in Python\n",
    "- Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "object_columns = list(df.select_dtypes(include='object').columns) \n",
    "object_columns.append('MasVnrArea')\n",
    "df2 = df.drop(object_columns, axis=1)\n",
    "\n",
    "# Impute null values\n",
    "df2['LotFrontage'].fillna(df2['LotFrontage'].mean(), inplace=True)\n",
    "df2['GarageYrBlt'].fillna(df2['GarageYrBlt'].median(), inplace=True)\n",
    "\n",
    "# Create y\n",
    "X = df2.drop(['SalePrice'], axis=1) \n",
    "y = df2['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(2), int64(35)\n",
      "memory usage: 422.1 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.8093010423144277\n",
      "MSE: 1105452189.6423388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_train)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale the data and perform train test split\n",
    "X_scale = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.8093009570358276\n",
      "MSE: 1105452683.9891164\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_train)\n",
    "r2_score(y_train, y_hat)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "X_cat=df[object_columns]\n",
    "X_cat.drop(['MasVnrArea'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummies\n",
    "X_cat = pd.get_dummies(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "5       143000\n",
       "6       307000\n",
       "7       200000\n",
       "8       129900\n",
       "9       118000\n",
       "10      129500\n",
       "11      345000\n",
       "12      144000\n",
       "13      279500\n",
       "14      157000\n",
       "15      132000\n",
       "16      149000\n",
       "17       90000\n",
       "18      159000\n",
       "19      139000\n",
       "20      325300\n",
       "21      139400\n",
       "22      230000\n",
       "23      129900\n",
       "24      154000\n",
       "25      256300\n",
       "26      134800\n",
       "27      306000\n",
       "28      207500\n",
       "29       68500\n",
       "         ...  \n",
       "1430    192140\n",
       "1431    143750\n",
       "1432     64500\n",
       "1433    186500\n",
       "1434    160000\n",
       "1435    174000\n",
       "1436    120500\n",
       "1437    394617\n",
       "1438    149700\n",
       "1439    197000\n",
       "1440    191000\n",
       "1441    149300\n",
       "1442    310000\n",
       "1443    121000\n",
       "1444    179600\n",
       "1445    129000\n",
       "1446    157900\n",
       "1447    240000\n",
       "1448    112000\n",
       "1449     92000\n",
       "1450    136000\n",
       "1451    287090\n",
       "1452    145000\n",
       "1453     84500\n",
       "1454    185000\n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df3 = pd.concat([df2, X_cat], axis=1)\n",
    "df3['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9377679845011461\n",
      "MSE: 360749312.0780114\n"
     ]
    }
   ],
   "source": [
    "X = df3.drop(['SalePrice'], axis=1)\n",
    "y = df3['SalePrice']\n",
    "\n",
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_train)\n",
    "r2_score(y_train, y_hat)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9377674304423264\n",
      "MSE: 360752523.87079144\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "X = df3.drop(['SalePrice'], axis=1)\n",
    "y = df3['SalePrice']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso_model = lasso.fit(X_train,y_train)\n",
    "\n",
    "y_hat = lasso_model.predict(X_train)\n",
    "r2_score(y_train, y_hat)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.937718090928288\n",
      "MSE: 361038537.3576586\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X = df3.drop(['SalePrice'], axis=1)\n",
    "y = df3['SalePrice']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=10)\n",
    "lasso_model = lasso.fit(X_train,y_train)\n",
    "\n",
    "y_hat = lasso_model.predict(X_train)\n",
    "r2_score(y_train, y_hat)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9377582360481548\n",
      "MSE: 360805822.3433829\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Your code here\n",
    "X = df3.drop(['SalePrice'], axis=1)\n",
    "y = df3['SalePrice']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge_model = ridge.fit(X_train,y_train)\n",
    "\n",
    "y_hat = ridge_model.predict(X_train)\n",
    "r2_score(y_train, y_hat)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9374066363411243\n",
      "MSE: 362843991.1447836\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "X = df3.drop(['SalePrice'], axis=1)\n",
    "y = df3['SalePrice']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge_model = ridge.fit(X_train,y_train)\n",
    "\n",
    "y_hat = ridge_model.predict(X_train)\n",
    "r2_score(y_train, y_hat)\n",
    "print(\"R2:\", r2_score(y_train, y_hat))\n",
    "print(\"MSE:\", mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?   \n",
    "\n",
    "Conclusions here\n",
    "\n",
    "Ridge, alpha=1 performed the best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 out of 288 params selected\n"
     ]
    }
   ],
   "source": [
    "# number of Ridge params almost zero\n",
    "ridge_params = pd.DataFrame(ridge_model.coef_, X_scale.columns, columns=['Coefficient'])\n",
    "ridge_close_to_0 = ridge_params.loc[(ridge_params.Coefficient > -1) & (ridge_params.Coefficient < 1)]\n",
    "print(len(ridge_params) - len(ridge_close_to_0), \"out of\", len(ridge_params), \"params selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 out of 288 params selected\n"
     ]
    }
   ],
   "source": [
    "# number of Lasso params almost zero\n",
    "lasso_params = pd.DataFrame(lasso_model.coef_, X_scale.columns, columns=['Coefficient'])\n",
    "lasso_close_to_0 = lasso_params.loc[(lasso_params.Coefficient > -1) & (lasso_params.Coefficient < 1)]\n",
    "print(len(lasso_params) - len(lasso_close_to_0), \"out of\", len(lasso_params), \"params selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645833333333334"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "249/288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
